{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-26T05:04:50.761085Z",
     "iopub.status.busy": "2024-11-26T05:04:50.760695Z",
     "iopub.status.idle": "2024-11-26T05:04:54.447615Z",
     "shell.execute_reply": "2024-11-26T05:04:54.446355Z",
     "shell.execute_reply.started": "2024-11-26T05:04:50.761049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:05:08.365738Z",
     "iopub.status.busy": "2024-11-26T05:05:08.365227Z",
     "iopub.status.idle": "2024-11-26T05:05:24.196866Z",
     "shell.execute_reply": "2024-11-26T05:05:24.195572Z",
     "shell.execute_reply.started": "2024-11-26T05:05:08.365701Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:05:29.752392Z",
     "iopub.status.busy": "2024-11-26T05:05:29.751738Z",
     "iopub.status.idle": "2024-11-26T05:06:17.572161Z",
     "shell.execute_reply": "2024-11-26T05:06:17.570874Z",
     "shell.execute_reply.started": "2024-11-26T05:05:29.752354Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def load_images_from_subfolders(base_dir, img_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif')  # Add any other extensions you need\n",
    "    for subfolder in os.listdir(base_dir):\n",
    "        subfolder_path = os.path.join(base_dir, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            for filename in os.listdir(subfolder_path):\n",
    "                file_path = os.path.join(subfolder_path, filename)\n",
    "                if os.path.isfile(file_path) and file_path.lower().endswith(valid_extensions):\n",
    "                    try:\n",
    "                        img = load_img(file_path, target_size=img_size)\n",
    "                        img_array = img_to_array(img) / 255.0\n",
    "                        images.append(img_array)\n",
    "                        labels.append(subfolder)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading {file_path}: {e}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Define the directory path and parameters\n",
    "base_dir = r'C:\\Users\\Ayman\\Desktop\\graduation\\Faulty_solar_panel'\n",
    "img_size = (224, 224)\n",
    "\n",
    "# Load images and labels\n",
    "images, labels = load_images_from_subfolders(base_dir, img_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:06:25.539781Z",
     "iopub.status.busy": "2024-11-26T05:06:25.539395Z",
     "iopub.status.idle": "2024-11-26T05:06:25.548245Z",
     "shell.execute_reply": "2024-11-26T05:06:25.546607Z",
     "shell.execute_reply.started": "2024-11-26T05:06:25.539745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#show shape of data\n",
    "print(images.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:06:29.556420Z",
     "iopub.status.busy": "2024-11-26T05:06:29.556062Z",
     "iopub.status.idle": "2024-11-26T05:06:29.562148Z",
     "shell.execute_reply": "2024-11-26T05:06:29.560934Z",
     "shell.execute_reply.started": "2024-11-26T05:06:29.556389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This will print all the labels in the dataset\n",
    "print(labels)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:06:31.715172Z",
     "iopub.status.busy": "2024-11-26T05:06:31.714750Z",
     "iopub.status.idle": "2024-11-26T05:06:31.722090Z",
     "shell.execute_reply": "2024-11-26T05:06:31.720885Z",
     "shell.execute_reply.started": "2024-11-26T05:06:31.715137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This will print the unique class labels\n",
    "import numpy as np\n",
    "unique_labels = np.unique(labels)\n",
    "print(unique_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:07:44.672320Z",
     "iopub.status.busy": "2024-11-26T05:07:44.671925Z",
     "iopub.status.idle": "2024-11-26T05:07:44.909032Z",
     "shell.execute_reply": "2024-11-26T05:07:44.907444Z",
     "shell.execute_reply.started": "2024-11-26T05:07:44.672285Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Function to display an image with its label\n",
    "def show_image_with_label(img_array, label):\n",
    "    plt.imshow(img_array)\n",
    "    plt.title(label)\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()\n",
    "\n",
    "# Display the first image and its label\n",
    "show_image_with_label(images[0], labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:08:48.615006Z",
     "iopub.status.busy": "2024-11-26T05:08:48.614607Z",
     "iopub.status.idle": "2024-11-26T05:34:41.036040Z",
     "shell.execute_reply": "2024-11-26T05:34:41.034898Z",
     "shell.execute_reply.started": "2024-11-26T05:08:48.614973Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Load a pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "def extract_features(img_array):\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    features = base_model.predict(img_array)\n",
    "    return features.flatten()\n",
    "\n",
    "# Extract features for all images\n",
    "features = []\n",
    "for img in images:\n",
    "    features.append(extract_features(img))\n",
    "features = np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:52:34.032282Z",
     "iopub.status.busy": "2024-11-26T05:52:34.031511Z",
     "iopub.status.idle": "2024-11-26T05:52:34.039636Z",
     "shell.execute_reply": "2024-11-26T05:52:34.038433Z",
     "shell.execute_reply.started": "2024-11-26T05:52:34.032246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels\n",
    "labels_encoded = le.fit_transform(labels)\n",
    "\n",
    "# Print the classes to check the encoding\n",
    "print(\"Class mappings:\", dict(zip(le.classes_, le.transform(le.classes_))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:52:36.148433Z",
     "iopub.status.busy": "2024-11-26T05:52:36.148061Z",
     "iopub.status.idle": "2024-11-26T05:52:43.813544Z",
     "shell.execute_reply": "2024-11-26T05:52:43.812408Z",
     "shell.execute_reply.started": "2024-11-26T05:52:36.148403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#deal with imbalance classes\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "features_resampled, labels_resampled = smote.fit_resample(features, labels_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:52:43.816093Z",
     "iopub.status.busy": "2024-11-26T05:52:43.815315Z",
     "iopub.status.idle": "2024-11-26T05:52:43.822915Z",
     "shell.execute_reply": "2024-11-26T05:52:43.822046Z",
     "shell.execute_reply.started": "2024-11-26T05:52:43.816057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "# Check the balance of the labels\n",
    "print(collections.Counter(labels_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:52:49.688353Z",
     "iopub.status.busy": "2024-11-26T05:52:49.687961Z",
     "iopub.status.idle": "2024-11-26T05:52:49.753368Z",
     "shell.execute_reply": "2024-11-26T05:52:49.752499Z",
     "shell.execute_reply.started": "2024-11-26T05:52:49.688318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#first model cnn\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "# Assuming 'features_resampled' and 'labels_resampled' are your resampled data\n",
    "input_shape = features_resampled.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(input_shape,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(np.unique(labels_resampled)), activation='softmax')  # Adjust the output layer according to your number of classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:52:51.600768Z",
     "iopub.status.busy": "2024-11-26T05:52:51.600370Z",
     "iopub.status.idle": "2024-11-26T05:52:51.866517Z",
     "shell.execute_reply": "2024-11-26T05:52:51.865574Z",
     "shell.execute_reply.started": "2024-11-26T05:52:51.600734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#ensure of dtye\n",
    "features_resampled = features_resampled.astype(np.float32)\n",
    "labels_resampled = labels_resampled.astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:52:56.683531Z",
     "iopub.status.busy": "2024-11-26T05:52:56.683169Z",
     "iopub.status.idle": "2024-11-26T05:53:46.422059Z",
     "shell.execute_reply": "2024-11-26T05:53:46.421176Z",
     "shell.execute_reply.started": "2024-11-26T05:52:56.683500Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the resampled data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(features_resampled, labels_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "history=model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:53:51.142748Z",
     "iopub.status.busy": "2024-11-26T05:53:51.142377Z",
     "iopub.status.idle": "2024-11-26T05:53:51.753078Z",
     "shell.execute_reply": "2024-11-26T05:53:51.751896Z",
     "shell.execute_reply.started": "2024-11-26T05:53:51.142717Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.grid(True)\n",
    "plt.plot(history.history['accuracy'], 'bo-', label='Train Accuracy')  # 'bo-' means blue color, round points, solid line\n",
    "plt.plot(history.history['val_accuracy'], 'ro-', label='Validation Accuracy')  # 'ro-' means red color, round points, solid line\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.grid(True)\n",
    "plt.plot(history.history['loss'], 'bo-', label='Train Loss')  # 'bo-' means blue color, round points, solid line\n",
    "plt.plot(history.history['val_loss'], 'ro-', label='Validation Loss')  # 'ro-' means red color, round points, solid line\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:54:34.137670Z",
     "iopub.status.busy": "2024-11-26T05:54:34.137230Z",
     "iopub.status.idle": "2024-11-26T05:54:34.189421Z",
     "shell.execute_reply": "2024-11-26T05:54:34.188313Z",
     "shell.execute_reply.started": "2024-11-26T05:54:34.137632Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# regluaization by l2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "# Get the input shape from the features\n",
    "input_shape = features_resampled.shape[1]\n",
    "\n",
    "# Define the model with L2 regularization\n",
    "model = Sequential([\n",
    "    Input(shape=(input_shape,)),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(len(np.unique(labels_resampled)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:55:19.774301Z",
     "iopub.status.busy": "2024-11-26T05:55:19.773925Z",
     "iopub.status.idle": "2024-11-26T05:56:23.298908Z",
     "shell.execute_reply": "2024-11-26T05:56:23.297919Z",
     "shell.execute_reply.started": "2024-11-26T05:55:19.774270Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:56:27.357933Z",
     "iopub.status.busy": "2024-11-26T05:56:27.357507Z",
     "iopub.status.idle": "2024-11-26T05:56:27.363789Z",
     "shell.execute_reply": "2024-11-26T05:56:27.362641Z",
     "shell.execute_reply.started": "2024-11-26T05:56:27.357897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training accuracy and loss\n",
    "train_accuracy = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "\n",
    "# Validation accuracy and loss\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:56:27.838604Z",
     "iopub.status.busy": "2024-11-26T05:56:27.838196Z",
     "iopub.status.idle": "2024-11-26T05:56:27.843965Z",
     "shell.execute_reply": "2024-11-26T05:56:27.842739Z",
     "shell.execute_reply.started": "2024-11-26T05:56:27.838560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:56:31.784691Z",
     "iopub.status.busy": "2024-11-26T05:56:31.784286Z",
     "iopub.status.idle": "2024-11-26T05:56:31.791594Z",
     "shell.execute_reply": "2024-11-26T05:56:31.790558Z",
     "shell.execute_reply.started": "2024-11-26T05:56:31.784657Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "avg_train_loss = np.mean(train_loss)\n",
    "avg_train_accuracy = np.mean(train_accuracy)*100\n",
    "avg_val_loss = np.mean(val_loss)\n",
    "avg_val_accuracy = np.mean(val_accuracy)*100\n",
    "print(f'Training Loss: {avg_train_loss:.4f}') \n",
    "print(f'Training Accuracy: {avg_train_accuracy:.4f}')\n",
    "print(f'Validation Loss: {avg_val_loss:.4f}')\n",
    "print(f'Validation Accuracy: {avg_val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:56:51.725437Z",
     "iopub.status.busy": "2024-11-26T05:56:51.725053Z",
     "iopub.status.idle": "2024-11-26T05:56:52.306956Z",
     "shell.execute_reply": "2024-11-26T05:56:52.305909Z",
     "shell.execute_reply.started": "2024-11-26T05:56:51.725403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'C:\\Users\\Ayman\\Desktop\\graduation\\Faulty_solar_panel.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load and resize image function\n",
    "def load_and_resize_image(image_path, target_size=(224, 224)):\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    if image is None:\n",
    "        print(\"Error: Could not load the image.\")\n",
    "        return None\n",
    "    \n",
    "    if image.size == 0:\n",
    "        print(\"Error: The image has zero dimensions.\")\n",
    "        return None\n",
    "    \n",
    "    resized_image = cv2.resize(image, target_size)\n",
    "    return resized_image\n",
    "\n",
    "# Image preprocessing function\n",
    "def preprocess_image(image):\n",
    "    image = image / 255.0  # Normalize pixel values\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# Path to your image\n",
    "image_path = r'C:\\Users\\Ayman\\Desktop\\graduation\\Faulty_solar_panel\\damage1.png'\n",
    "\n",
    "# Load and resize image\n",
    "processed_image = load_and_resize_image(image_path, target_size=(224, 224))\n",
    "\n",
    "if processed_image is not None:\n",
    "    print(\"Image processed successfully.\")\n",
    "    \n",
    "    # Preprocess the image for the model\n",
    "    processed_image = preprocess_image(processed_image)\n",
    "    \n",
    "    # Load your pre-trained model\n",
    "    model = load_model(r'C:\\Users\\Ayman\\Desktop\\graduation\\Faulty_solar_panel.h5')\n",
    "    \n",
    "    # Ensure the input shape matches the model's expected input shape\n",
    "    assert model.input_shape == (None, 224, 224, 3), \"Input shape does not match the model's expected input shape.\"\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = model.predict(processed_image)\n",
    "\n",
    "    # Example: If your model outputs probabilities for multiple classes\n",
    "    predicted_class = np.argmax(prediction, axis=1)\n",
    "\n",
    "    print(f'Predicted class: {predicted_class}')\n",
    "else:\n",
    "    print(\"Error: Image could not be processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def load_and_resize_image(image_path, target_size=(224, 224)):\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    if image is None:\n",
    "        print(\"Error: Could not load the image.\")\n",
    "        return None\n",
    "    \n",
    "    if image.size == 0:\n",
    "        print(\"Error: The image has zero dimensions.\")\n",
    "        return None\n",
    "    \n",
    "    resized_image = cv2.resize(image, target_size)\n",
    "    return resized_image\n",
    "\n",
    "image_path = r'C:\\Users\\Ayman\\Desktop\\graduation\\Faulty_solar_panel\\damage1.png'\n",
    "processed_image = load_and_resize_image(image_path, target_size=(224, 224))\n",
    "\n",
    "if processed_image is not None:\n",
    "    print(\"Image processed successfully.\")\n",
    "else:\n",
    "    print(\"Error: Image could not be processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load your pre-trained model\n",
    "model = load_model(r'C:\\Users\\Ayman\\Desktop\\graduation\\Faulty_solar_panel.h5')\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    # Ensure the image is loaded correctly\n",
    "    if image is None:\n",
    "        raise ValueError(\"Error: Could not load the image.\")\n",
    "    \n",
    "    # Resize image to target size\n",
    "    image = cv2.resize(image, target_size)\n",
    "    # Normalize pixel values\n",
    "    image = image / 255.0\n",
    "    # Add batch dimension\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "# Example usage\n",
    "image_path = r'C:\\Users\\Ayman\\Desktop\\graduation\\Faulty_solar_panel\\damage1.png'\n",
    "processed_image = preprocess_image(image_path)\n",
    "\n",
    "# Ensure the input shape matches the model's expected input shape\n",
    "assert model.input_shape == (None, 224, 224, 3), \"Input shape does not match the model's expected input shape.\"\n",
    "\n",
    "# Make a prediction\n",
    "prediction = model.predict(processed_image)\n",
    "\n",
    "# Example: If your model outputs probabilities for multiple classes\n",
    "predicted_class = np.argmax(prediction, axis=1)\n",
    "\n",
    "print(f'Predicted class: {predicted_class}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install jinja2==3.0.3 --force-reinstall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markupsafe import escape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from markupsafe import escape  # Correct import\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load your pre-trained model\n",
    "model = load_model(r'C:\\Users\\Ayman\\Desktop\\graduation\\Faulty_solar_panel.h5')\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Normalize pixel values\n",
    "    image = image / 255.0\n",
    "    # Add batch dimension\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "def load_and_resize_image(image_path, target_size=(224, 224)):\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    if image is None:\n",
    "        print(\"Error: Could not load the image.\")\n",
    "        return None\n",
    "    \n",
    "    if image.size == 0:\n",
    "        print(\"Error: The image has zero dimensions.\")\n",
    "        return None\n",
    "    \n",
    "    resized_image = cv2.resize(image, target_size)\n",
    "    return resized_image\n",
    "\n",
    "def predict(image):\n",
    "    # Preprocess the image\n",
    "    processed_image = preprocess_image(image)\n",
    "    \n",
    "    # Ensure the input shape matches the model's expected input shape\n",
    "    assert model.input_shape == (None, 224, 224, 3), \"Input shape does not match the model's expected input shape.\"\n",
    "    \n",
    "    # Make a prediction\n",
    "    prediction = model.predict(processed_image)\n",
    "    \n",
    "    # Example: If your model outputs probabilities for multiple classes\n",
    "    predicted_class = np.argmax(prediction, axis=1)\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict_endpoint():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({\"error\": \"No file part\"}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "\n",
    "    if file.filename == '':\n",
    "        return jsonify({\"error\": \"No selected file\"}), 400\n",
    "\n",
    "    # Save the uploaded file to a temporary location\n",
    "    file_path = 'temp_image.png'\n",
    "    file.save(file_path)\n",
    "    \n",
    "    # Load and resize the image\n",
    "    image = load_and_resize_image(file_path, target_size=(224, 224))\n",
    "\n",
    "    if image is not None:\n",
    "        # Predict the class of the image\n",
    "        predicted_class = predict(image)\n",
    "        return jsonify({\"prediction\": int(predicted_class[0])})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Image could not be processed.\"}), 400                             \n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4936001,
     "sourceId": 8309526,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
